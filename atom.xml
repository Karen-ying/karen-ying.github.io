<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Secrets of Strawberry</title>
  
  <subtitle>樱花落下的速度是每秒5厘米</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-11-30T15:57:32.042Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Karen</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>GMM</title>
    <link href="http://example.com/2021/11/30/GMM/"/>
    <id>http://example.com/2021/11/30/GMM/</id>
    <published>2021-11-30T01:29:59.000Z</published>
    <updated>2021-11-30T15:57:32.042Z</updated>
    
    <content type="html"><![CDATA[<h1>Generalized Method of Moments(GMM)</h1><p>OLS估计量成立的重要条件：解释变量与扰动项不相关，即$E(\epsilon_t X_t) \neq 0$（前定变量的假设）。</p><p>否则，OLS估计量将不一致，OLS估计量不会收敛到真实的总体参数。</p><h2 id="1-内生性来源">1. <strong>内生性来源</strong></h2><h3 id="1-1-与滞后因变量的自相关">1.1 <strong>与滞后因变量的自相关</strong></h3><p>例如，利率模型给定：</p><p>$$y_t = \beta_1 + \beta_2 x_t +\beta_3 y_{t-1} + \epsilon_t$$</p><p>假设$\epsilon_t $ 服从一阶自相关，即：</p><p>$$\epsilon_t = \rho \epsilon_{t-1} + v_t$$</p><p>则这个模型就可以写成：</p><p>$$y_t = \beta_1 + \beta_2 x_t + \beta_3 y_{t-1} + \rho \epsilon_{t-1} + v_t$$</p><p>原公式左右两边同时滞后一期：</p><p>$$y_{t-1} = \beta_1 + \beta_2 x_{t-1} + \beta_3 y_{t-2} + \epsilon_{t-1}$$</p><p>可以看到误差项$\epsilon_t$与 $y_{t-1}$ 相关，OLS估计量不再是一致估计量，而是有偏的。</p><h3 id="1-2-度量误差">1.2 <strong>度量误差</strong></h3><ul><li>由于关键变量的度量上存在误差，使其与真实值之间存在偏差，这种偏差可能会成为回归误差（regression error）的一部分，从而导致内生性问题。</li></ul><p>假设因变量为$y_t $，自变量为 $w_t $:</p><p>$$y_t = \beta_1 + \beta_2 w_t + v_t$$</p><p>$$x_t = w_t + u_t$$</p><p>$$y_t = \beta_1 + \beta_2 x_t + \epsilon_t$$</p><p>where $\epsilon_t = v_t -\beta_2 u_t$</p><p>此时参数$\beta_2$ 的估计量是有偏的、不一致的。</p><h3 id="1-3-遗漏变量">1.3 <strong>遗漏变量</strong></h3><p>如果遗漏的变量与其他解释变量不相关，一般不会造成问题。否则，就会造成解释变量与残差项相关，从而引起内生性问题。</p><p>考虑个人工资的等式：</p><p>$$y_i = x_{1i} ^{\prime} \beta_1 + x_{2i} \beta_2 + u_i \gamma + v_i $$</p><p>$y_i$代表个人工资取log，$x_{1i}$代表个人特征的向量（包括一个截距项），$x_{2i}$代表上学年限。$u_i$代表不可观测的变量，反映一个人的能力。</p><p>因为$u_i$是不可观测的，所以计量经济学者会简单进行估计：</p><p>$$y_i = x_i ^{\prime} \beta + \epsilon_i$$</p><p>where $\epsilon_i = u_i \gamma + v_i$</p><p>这就将遗失变量的影响归结到误差项中，$\epsilon_i$与受教育程度存在相关性，导致内生性问题。</p><h4 id="1-4-联立方程偏差">1.4 <strong>联立方程偏差</strong></h4><p>考虑以下联立方程模型：</p><p>(i) $c_t (消费) = b y_t (收入) + u_t, 0 \leq \beta(边际消费倾向) \leq 1$</p><p>(ii) $y_t = c_t + i_t$ (收入 = 消费 + 投资)</p><p>由于$u_t \rightarrow c_t \rightarrow y_t (ii式) \rightarrow y_t (i式)$，</p><p>此时产生了联立方程偏差，$^{b}$ 是有偏的，因为$E(y_tu_t) \neq 0$, 不能用OLS估计。</p><p>OLS方法在联立方程是有偏不一致的，这是由于内生性导致的，即使是大样本也不能解决。</p><h2 id="2-工具变量法">2. <strong>工具变量法</strong></h2><p>由于$E(X_i,u_i) \neq 0 \rightarrow$ 内生性，所以OLS为有偏估计。工具变量（IV）即找到$x_i$的替代品就是工具变量**（和$x_i$相关，但跟误差项$u_i$无关）**</p><h3 id="2-1-IV的推导——方程性质">2.1 <strong>IV的推导——方程性质</strong></h3><p>在此联立方程中：</p><p>(i) $c_t  = b y_t  + u_t, 0 \leq \beta \leq 1$</p><p>(ii) $y_t = c_t + i_t$ (收入 = 消费 + 投资)</p><p>所有变量可以分为内生变量和前定变量。内生变量为解出来的两个解：$c_t, y_t$,前定变量可分为外生变量（$i_t$）和内生变量滞后项（在此联立方程中没有）。</p><p>若$E(y_t u_t) = 0, E(y_t(c_t - b y_t)) = 0$</p><p>$$\hat{b} = (y ^{\prime} y)^{-1} y{\prime} c= \frac{\sum{c_t y_t}}{\sum{y_t ^2}}$$</p><p>将$i_t$作为式(i)中的工具变量,即$E(i_t u_t) = 0, E(i_t(c_t - b y_t)) = 0$,则</p><p>$$\tilde{b} =(i ^{\prime} y) i^{\prime} c = \frac{\sum{i_t c_t}}{\sum i_t y_t} $$</p><p>$\tilde{b}$就是$b$的估计量，且</p><p>$$p lim \quad \tilde{b} - b = 0$$</p><blockquote><p>假设式中只有一部分被替代成为工具变量的情况：</p></blockquote><p>考虑以下模型：</p><p>$$y_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + u_i$$</p><p>在此模型中，$x_{1i}$无内生性，$x_{2i}$有内生性，即$E(X_{1i} u_i) =  0, E(X_{2i} u_i) \neq  0 $</p><p>令$z_{2i}$为工具变量，$E(Z_{2i} u_i) = 0$</p><p>可以建立以下方程：</p><p>$$<br>y=\begin{cases}<br>\frac{1}{N} \sum [x_{1i}(y_i - \beta_1 x_{1i}- \beta_1 x_{2i})] = 0\\<br>\frac{1}{N} \sum [z_{2i}(y_i - \beta_1 x_{1i}- \beta_1 x_{2i})] = 0<br>\end{cases}<br>$$</p><p>$\Rightarrow \tilde{b} = (z^{\prime}x)^{-1} z^{\prime} y$</p><p>Ps: 工具变量$Z$由两部分组成，$Z = [X_{1i},z_{2i}]$，维度大于解释变量维度。</p><h3 id="2-2-IV的推导——矩阵性质">2.2 <strong>IV的推导——矩阵性质</strong></h3><p>给定模型：</p><p>$$y = Xb + u$$</p><p>两边同乘$X^{\prime}$,得到</p><p>$$X^{\prime} y = X^{\prime} Xb + X^{\prime} u$$</p><p>如果plim$(\frac{1}{n} X^{\prime} u) \neq 0$,那么$b$的估计量就是不一致的。</p><p>考虑一个(n×k)维的工具变量矩阵z，满足<strong>3个假定：</strong></p><ul><li>① p lim$(\frac{1}{n} Z^{\prime} u) = 0$</li><li>② p lim$(\frac{1}{n} Z^{\prime} X) = \sum$</li><li>③ p lim$(\frac{1}{n} Z^{\prime} Z) = \sum^*$</li></ul><p>($\sum 和 \sum^* $存在且为非奇异的，即保证逆矩阵的存在)</p><p>在方程 $y = Xb + u$ 两边同乘 $Z^{\prime}$,则有：</p><p>$$Z^{\prime} y = Z^{\prime} Xb + Z^{\prime} u$$</p><p>如果p lim$(\frac{1}{n} Z^{\prime} u) = 0$，那么</p><p>$$\hat{b}^{IV} = (Z^{\prime} X)^{-1} Z^{\prime} y$$</p><p>就是在工具变量估计下的b值。</p><p>工具变量估计的b值是一致的：</p><p>$$\hat{b}^{IV} = (Z^{\prime} X)^{-1} Z^{\prime} (Xb + u)$$<br>$$p lim(\hat{b}^{IV}) = b$$</p><h2 id="3-两阶段最小二乘法">3. <strong>两阶段最小二乘法</strong></h2><p>（<strong>全部变量都有内生性</strong>）$E(X_t \epsilon_t) \neq 0$</p><p>(i) $y_t  = \beta_0 + \beta_1 X_t  + \epsilon_t$</p><p>(ii) $X_t = y_t + i_t$</p><p>$X_k$即$X_t$,$Z$代表原模型中所有的前定变量。</p><p>$X_k = Z \pi_k + v_k$</p><p>$\hat{\pi}_k = {(Z^{\prime} Z)^{-1}Z^{\prime}X}$</p><p>$\hat{X} = Z \hat{\pi}_k = Z {(Z^{\prime} Z)^{-1}Z^{\prime}X}$</p><p>把$\hat{X}$代入原方程再进行第二次估计，得到</p><p>$\hat{\beta}_{IV} = (\hat{X}^{\prime} \hat{X})^{-1} \hat{X}^{\prime} y$</p><p>(<strong>多一个外生变量的结果</strong>*——影响简化方程的估计结果)</p><p>$\hat{\beta}_{IV} = (X^{\prime} Z(Z^{\prime}Z)^{-1}Z^{\prime} X)^{-1}X^{\prime}Z(Z^{\prime} Z)^{-1}y$</p><h2 id="4-GMM证明">4.GMM证明</h2><p>【让样本矩达到0，使得$X_i \epsilon_i = 0$】</p><p>在方程：</p><p>$$Y_i = Z^{\prime}_i \delta + \epsilon_i$$</p><p>中，Z是一个L维的解释变量。令工具变量为X.</p><p>由于矩条件(Orthogonality conditions/ Moment condition)：</p><p>$$E(Z_i \epsilon_i) \neq 0$$</p><p>对于工具变量X (K维的工具变量向量), 要求矩条件为：</p><p>$$E(X_i \epsilon_i) =  E[X_i (Y_i - Z^{\prime}_i \delta)] = 0$$</p><p>或 E($g_i$) = 0, $g_i = X_i \epsilon_i$, $g_i$是一个函数，工具变量与$\epsilon_i$正交时形成$g_i$</p><p>$$g_i = g(w_i; \delta)$$</p><p>其中，X、Y、Z统称为$w_i$,$w_i$是平稳的。</p><p>矩估计就是选择参数使得相关的样本矩为0.</p><p>总体矩为$E(g(w_i; \delta))$,他的样本矩就是在某个待估参数$\hat{\delta}$下$g(w_i; \delta)$的均值.($g(w_i; \delta) = x_i (y_i - z^{\prime}_i \delta)$)</p><p>$$g_n(\tilde{\delta}) = \frac{1}{n} \sum_{i=1}^{n}{g(w_i; \tilde{\delta})}$$</p><p>让样本矩为0，求 $\delta$</p><p>因为方程是线性的，$g_n(\tilde{\delta})$可以写成：</p><p><img src="https://i.loli.net/2021/11/30/Wv4bXQuUwOCYjZK.png" alt="gs"></p><p>则：</p><p>$$s_{xy} = s_{xz}\tilde{\delta}$$</p><p>注：如果$z_i = X_i$, 则mm = ols; 如果$k = l$, 则mm = IV估计结果；当过度识别时，IV失效，用GMM</p><p>所以对于大样本下的K=L,$s_{xy} = s_{xz}\tilde{\delta}$有唯一解，和IV结果一模一样：</p><p><img src="https://i.loli.net/2021/11/30/8Mifct1NTbXAphz.png" alt="gs"></p><p>如果等式是过度识别,即当K ＞ L时,要选择$\tilde{\delta}$让$g(\tilde{\delta})$无限接近于0.</p><p>目标函数为：<br>$$(\xi - \eta)^{\prime}\hat{W}(\xi - \eta)$$</p><p>则：</p><p>$$<br>\begin{align*}<br>J(\tilde{\delta},\hat{W}) &amp;= n · g_n(\tilde{\delta})^{\prime} \hat{W} g_n(\tilde{\delta})\\<br>&amp;= n · (s_{xy} - s_{xz}\tilde{\delta})^{\prime} \hat{W} (s_{xy} - s_{xz}\tilde{\delta})\\<br>&amp;= n ·s_{xy}^{\prime}·\hat{W}·s_{xy} - n ·(s_{xz}\tilde{\delta})^{\prime}·\hat{W}·s_{xy} - n ·s_{xy}^{\prime}·\hat{W}·s_{xz}\tilde{\delta} +  n ·(s_{xz}\tilde{\delta})^{\prime}·\hat{W}·s_{xz}\tilde{\delta}<br>\end{align*}<br>$$</p><p>GMM estimator:<br>$$<br>\frac{\partial{J}}{\partial{\tilde{\delta}}} = 0 \Rightarrow (s_{xz}^{\prime} \hat{W} s_{xz})^{-1} s_{xz}^{\prime}\hat{W} s_{xy}<br>$$</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;Generalized Method of Moments(GMM)&lt;/h1&gt;
&lt;p&gt;OLS估计量成立的重要条件：解释变量与扰动项不相关，即$E(\epsilon_t X_t) \neq 0$（前定变量的假设）。&lt;/p&gt;
&lt;p&gt;否则，OLS估计量将不一致，OLS估计量不会</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Literature - Credit Scoring</title>
    <link href="http://example.com/2021/11/28/Litrature-Credit-Scoring/"/>
    <id>http://example.com/2021/11/28/Litrature-Credit-Scoring/</id>
    <published>2021-11-28T09:41:46.000Z</published>
    <updated>2021-11-28T12:42:23.505Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Machine-Learning-approach-for-Credit-Scoring-2020"><a href="#Machine-Learning-approach-for-Credit-Scoring-2020" class="headerlink" title="Machine Learning approach for Credit Scoring (2020)"></a>Machine Learning approach for Credit Scoring (2020)</h1><p>期刊：working paper </p><p>作者：A. R. Provenzano∗, D. Trifir`o, A. Datteo, L. Giada, N. Jean, A. Riciputi,G. Le Pera, M. Spadaccino, L. Massaron and C. Nordio</p><p>文章链接：<a href="https://arxiv.org/pdf/2008.01687">https://arxiv.org/pdf/2008.01687</a></p><h2 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h2><ul><li>在对公司进行不平衡样本处理后结合经济指标运用<strong>机器学习/人工智能</strong>的方法对违约公司进行分类，用到<strong>embedding和自编码器</strong>这类自然语言处理技术处理经济部分的文本描述。最后运用<strong>遗传算法</strong>(差异进化，DE)进行信用评级。模型的可解释性是通过实现<strong>Sharp和LIME</strong>来实现的，是一种局部解释方法。</li></ul><p><strong>技术：</strong> Autoencoders, Embedding, LightGBM, Differential Evolution, SHAP, LIME</p><h2 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h2><ul><li>数据跨度：2011-2017年度179个特征。</li><li>来源：穆迪提供的信贷研究数据库(CRD)，包括919,636份年度（年底）<strong>财务报表</strong>，其中157,986家意大利公司属于<strong>不同部门</strong>(如汽车、教育、消费品、不耐用品、能源、高等教学行业、媒体等。不包括消防部门，即金融、保险和房地产部门)。</li></ul><h2 id="相关细节"><a href="#相关细节" class="headerlink" title="相关细节"></a>相关细节</h2><blockquote><p>特征选择</p></blockquote><ul><li><p>选用了很多财务指标，是一个<strong>二分类问题（破产超过一年周期的为1）</strong>，其他为0。</p><p>由于业务周期可以对企业的盈利能力产生很大的影响，并影响其风险概况，因此将原始信息与更一般的<strong>宏观变量（2年滞后的历史数据）</strong> 结合起来。</p></li></ul><p><img src="https://i.loli.net/2021/11/28/9HysEVFTvrGOUIC.png" alt="数据划分的图"></p><blockquote><p>处理类别数据的方法</p></blockquote><ol><li><p><code>Label Encoding</code></p><p> 把类别数据按找顺序编码，但是不同样本数据不存在顺序关系，会误导模型的训练。</p></li><li><p><code>One-Hot Encoding</code>: </p><p>内存效率低下的编码，这种稀疏表示并不能保持特征值之间的相似性。</p></li><li><p><code>Categorical Embedding</code> </p></li><li><p><code>Word Embedding</code>  —— Sentence Embedding</p><p>为了保证原始数据的“语义”并在低维空间中工作，这篇文章提出了一种自编码器正则化嵌入的框架——<code>NACE code</code>(将完整的句子转化为向量)，其中原始数据被嵌入成低维向量。</p></li><li><p><code>Target encoding</code>: </p><p>这允许编码任意数量的特征，而不增加数据维数。然而，作为一个缺点，这种类型的编码的简单应用程序可能允许<strong>数据泄漏</strong>，从而导致模型<strong>过拟合</strong>，预测性能较差。</p><p>为防止数据泄漏而开发的目标编码算法称为<code>James-Stein estimator</code>，<strong>是这篇文章中模型使用的目标编码算法</strong>。</p><ul><li>更详细地说，它用一个观测特征值的平均目标值和平均目标值的平均值来转化分类特征，计算与特征实现无关。</li></ul></li></ol><blockquote><p>特征重要性</p></blockquote><p>在特征转化后会导致输入特征的维度大幅度增加，这篇文章采用了投票集成模型（a voting ensemble of models）来独立分配特征的重要性，并有效选择那些对模型贡献最大的特征。  </p><h2 id="Satellite-models"><a href="#Satellite-models" class="headerlink" title="Satellite models"></a>Satellite models</h2><ul><li>对行业部门的描述进行句子嵌入</li><li>通过堆叠自编码器降低嵌入维度</li><li>通过投票方法选择相关的重要特征</li></ul><blockquote><p>对行业部门的描述进行句子嵌入</p></blockquote><p>预训练模型来自<a href="https://realpython.com/natural-language-processing-spacy-python/">SpaCy NLP</a>包,嵌入NACE行业部门的文本，每个文本序列为300维。</p><p><img src="https://i.loli.net/2021/11/28/EVj7Rd6nStLq9Wa.png" alt="具体步骤"></p><blockquote><p>通过堆叠自编码器降低嵌入维度</p></blockquote><p>通过tensorflow框架下的集成自编码器模型<em>stacked autoencoder(SAE)</em> （6层）将嵌入维度降低为5维。</p><p>与PCA不同，由于它们通过使用非线性激活函数和多层结构甚至可以学习非线性变换，因此自动编码器是降维的有效工具。此外，在此应用中，SAE表现出<strong>低重建损失</strong><a href="%E9%87%8D%E5%BB%BA%E6%8D%9F%E8%80%97%E6%98%AF%E6%8D%9F%E8%80%97%E5%87%BD%E6%95%B0%EF%BC%88%E9%80%9A%E5%B8%B8%E6%98%AF%E9%87%8D%E5%BB%BA%E8%BE%93%E5%87%BA%E5%92%8C%E8%BE%93%E5%85%A5%E4%B9%8B%E9%97%B4%E7%9A%84%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE%E6%88%96%E4%BA%A4%E5%8F%89%E7%86%B5%EF%BC%89%EF%BC%8C%E5%AE%83%E6%83%A9%E7%BD%9A%E7%BD%91%E7%BB%9C%E5%88%9B%E5%BB%BA%E4%B8%8E%E5%8E%9F%E5%A7%8B%E8%BE%93%E5%85%A5%E4%B8%8D%E5%90%8C%E7%9A%84%E8%BE%93%E5%87%BA.">^1</a> （约占MSE的6%），这与PCA解释的低方差相反。</p><blockquote><p>通过投票方法选择相关的重要特征</p></blockquote><p>特征选择的算法通常被分为三类：</p><ol><li><p><strong>Fiter-based method</strong></p><p>应用统计度量为每个特征分配分数，数据集的变量根据其分数进行排名，选择保留或删除的变量。</p></li></ol><ul><li>eg. Pearson criterion, Chi-squared criterion</li></ul><ol start="2"><li><p><strong>Wrappered-based method</strong></p><p>将特征选择视为<em>搜索问题</em> 形成不同的组合并评估比较，根据模型准确性分数分配特征组合的分数。</p></li></ol><ul><li>eg. Recususive Feature Elimination(RFE), Random Forest Classifier(RF),Light-GBM(LGBM)</li></ul><ol start="3"><li><p><strong>Embedded-based method</strong></p><p>学习在建模时哪些特征对于模型准确率的贡献率最大。</p></li></ol><ul><li>eg. Logistic Lasso Regression</li></ul><p><strong>这篇文章集成了以上六种实例模型，将每种算法堆叠投票框架中，选择了在所有模型中排名最高的特征。</strong></p><h2 id="模型框架"><a href="#模型框架" class="headerlink" title="模型框架"></a>模型框架</h2><p>应用了三个串联的模型实现公司状态的分类和内部校准的评级系统，其中每个评级对应于相应的违约概率。</p><ol><li>第一个Boosted Tree algorithnm （这篇文章用的LGBM）对一年内的公司状态进行分类（0/1）</li></ol><blockquote><p>Tips: 由于违约和非违约之间的高度不平衡，运用修改后的对数不平衡损失，具体是将LightGBM的参数<em>scale_pos_weight</em> 设置为0和1之间的比率。目标函数采用了<em>Focal Loss</em> 或者常规的目标函数并没有显示对于不平衡样本有什么优势。</p></blockquote><ol start="2"><li>第二个模型的目的是将二进制分类器的输出分数拟合到实际的违约概率。构建了一个校准器，该校准器由在提升树的叶子分配上训练的逻辑回归组成。（灵感来源于<a href="http://quinonero.net/Publications/predicting-clicks-facebook.pdf">Xinran He et al.</a>）</li></ol><ul><li>【将 LGBM 分类器的每个单独树的输出视为一个分类特征，该特征将实例最终落入的叶子的索引作为值。应用了 one-hot 编码来获得虚拟变量，指示适合 LR 模型的叶子分配。最后，我们在以前用于LGBM训练阶段的列车组上测试了校准器。这种使用中间结果并将输出从分类更改为回归的方法类似于目前称为<strong>深度神经网络世界中的迁移学习</strong>，其中<em>最终的神经网络层被删除并被新的输出所取代</em> 。这种方法的主要优点是保留了系统在原始训练任务中学到的所有内部复杂特征工程，并将其转移到不同的问题，在我们的特定情况下，预测实际违约率。<br>】</li></ul><ol start="3"><li>通过遗传算法将重新拟合的<strong>违约概率拆分为9个聚类</strong>，从而校准评级系统。</li></ol><p><img src="https://i.loli.net/2021/11/28/CeVxToIRi852bc3.png" alt="遗传算法"></p><ol start="4"><li>最后用了<strong>SHAP值和LIME值</strong>对特征进行了解释</li></ol><p><img src="https://i.loli.net/2021/11/28/SsdvZ7X64WeuLMB.png" alt="LIME"></p><p><img src="https://i.loli.net/2021/11/28/xWoOzdvLZt8mufl.png" alt="SHAP"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Machine-Learning-approach-for-Credit-Scoring-2020&quot;&gt;&lt;a href=&quot;#Machine-Learning-approach-for-Credit-Scoring-2020&quot; class=&quot;headerlink&quot; t</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>期待</title>
    <link href="http://example.com/2021/04/18/%E6%9C%9F%E5%BE%85/"/>
    <id>http://example.com/2021/04/18/%E6%9C%9F%E5%BE%85/</id>
    <published>2021-04-18T15:53:32.000Z</published>
    <updated>2021-11-27T08:23:15.206Z</updated>
    
    <content type="html"><![CDATA[<p>   你要成为自己人生的决策者，而不是将期待予以他人。</p><p>   期待，其实是一个很美好的词。正是因为对所在乎的人有所期待，生活也就好像会有希望。作为学生的自己，会有这样的心理：期待自己的努力能够得到自己在乎的人的认可，当他们鼓励和肯定我时，我就会有满满的动力，周围都会有很多美丽的泡泡。但“期待”一词，带给我的不只是美好的一面，也会在不经意间让自我丧失了自己的自主权、自己的独立思考能力。长辈期待你在体制内工作，团队期待你能按照群体的思维方式做事，朋友期待你有共同的爱好。若是为了别人的期待活着，在每一次品尝到相应的甜味后，总是会继续按照别人的期待寻找自己身上下一个点应该如何改善。在这样的过程中，自己逐渐会活成他人眼中最应该成为的自己。这似乎是一个不错的选择，因为我们无法改造社会，我们只能适应社会。网上有很多鸡汤都会说，只愿归来仍是少年。可是据我观察，大多数人其实连生活都顾不上，又何来“重返少年感”呢？可是，就像蔡永康所说的那样，我们每个人都需要一个面具，最好的面具是能让你很舒服地呼吸又不会觉得难受的。我渐渐懂得了这一道理，但是在面具之下，选择让自己开心、放掉无谓的期待，才会是有好好照顾今生第一次的自己。</p><p>  既有来自于他人的期待，也有自己对于别人的期待。期待爱与被爱，期待自己在重要的人心中会有所不同，期待外界的认可…….当一个人很在乎这些东西时，会很细心地在乎很多细节。我们很容易为一些验证自己想法的细节而开心，却会因为发现击碎自己期待的细节，而长久陷入对他人或自我的怀疑。其实这都没有错，人与人之间的关系本就是错综复杂的。但是我想说，放弃对任何人的期待吧，就算是再亲近的人，也会有不愿意让你看到的一面，如果他在乎你，你可能不知道此时此刻在你面前的他，已经是尽力脚踩阴影却仍然愿意把阳光洒落在你身上的他。如果说成长带给我什么，我想说是感激。每每当我回家，我会发现很多父母对我爱的细节，这些细节让我无论在何处想起来都会觉得无以为报。曾期待母亲能对我再耐心一点，可是换一个角度想，她在一些小事上对很多人都很耐心，唯独对我不耐心，而这可能就是我所能提供的小小的情绪价值。期待与感激之间的转换，会让很多事情都释然。没有人理解自己没有关系，自己能理解自己，同时，也要去尽力理解他人。</p><p>  希望以后的自己能尽量放低对别人的期待，做自己想法的决策者，也可以是一个很cool的小颖呀。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;   你要成为自己人生的决策者，而不是将期待予以他人。&lt;/p&gt;
&lt;p&gt;   期待，其实是一个很美好的词。正是因为对所在乎的人有所期待，生活也就好像会有希望。作为学生的自己，会有这样的心理：期待自己的努力能够得到自己在乎的人的认可，当他们鼓励和肯定我时，我就会有满满的动力，周</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>今生是第一次</title>
    <link href="http://example.com/2021/04/04/%E4%BB%8A%E7%94%9F%E6%98%AF%E7%AC%AC%E4%B8%80%E6%AC%A1/"/>
    <id>http://example.com/2021/04/04/%E4%BB%8A%E7%94%9F%E6%98%AF%E7%AC%AC%E4%B8%80%E6%AC%A1/</id>
    <published>2021-04-04T08:34:51.000Z</published>
    <updated>2021-11-27T08:21:01.252Z</updated>
    
    <content type="html"><![CDATA[<p>  频繁记录着，因为热爱生活？嗯，我要朝这个目标努力。</p><p>《今生是第一次》可以说是一部很治愈的韩剧啦，虽然还没有看完，但是现在写一写感受也不为过叭。</p><p>从前总觉得时间是一种很残忍的东西，因为亲人、好朋友或是自己都会因为时间而消失或改变。每当很美好的时刻，常常会觉得，要是时间暂停在这一刻就好了，然而时间从没听过任何人的意见。</p><p>这部剧其实和很多韩剧不太一样，没有车祸的桥段，却显得很romantic。结婚是为了什么呢？是因为爱吗，剧中的男女主因为彼此有对方需要的东西而行使了婚姻这一形式，看起来好像很荒唐吧。因为有了“我们”，有了在孤寂的城市中被人需要的感觉，所以即使互相之间不喜欢，他们决定结婚。</p><p><img src="https://pic3.zhimg.com/v2-6018149431a4c59a9dd3b1a965b2dfe9_r.jpg?source=1940ef5c"></p><p>婚礼的前一刻，剧中的男主作出的是不会干涉智浩的任何决定，并且永远都会坚定地支持他的保证。而不是每场婚礼新郎都会说的：我会让她幸福的，我会保护她的。和很多泡沫剧不同，其实这更接近于现实。在这个时代，每个人让自己幸福都很难，又何谈通过婚姻的形式给与另一个人幸福呢？将自己的幸福依附于他人之上，本身就是一件极为不靠谱的事情。这样又显得，每个人都是孤独的个体。</p><p>今生对每个人来说，都只有一次。就像我现在书写的此刻，也终将逝去，那为什么不充满勇气地去做自己想做的事情呢？反正今生只有一次呀。我们面对的每个人，也都是今生第一次，当他走进你的生命时，也就意味着他带着他的过去、现在以及未来走进了你的世界。生命是脆弱的，但又同时是坚强的，温柔美好的事物纵然被喜欢，但苦难与挫折也成就一个人的独特的心性。每一时刻都有意义，认识自己比认识他人更为重要。</p><p>对于梦想，我想每个人都会对这句台词有或多或少的感同身受吧。“就算再要好，也有不想让对方见到的一面。有时也会感觉到，家人是这个世界上离我最远的人。当我下定决心为了梦想奋斗的时候，我以为我的人生，就是要独自走过这黑暗的隧道，但也没想到会是这么黑暗，也没想到会是这么孤单，到底…到底还要走多远。” 但是呢，每个人都应该有自己“装星星的口袋”，“在这平淡的人生中，会有一些闪耀的瞬间，这种时候不要忘记，把它存放在“装星星的口袋”中，这样以后疲惫、厌倦的时候，就看看这些星星，才能挺过难熬的日子。”</p><p>这部剧还是挺值得推荐的。</p><p><img src="https://pic3.zhimg.com/80/v2-8a828da222fcb99bbedfa39e9176dc38_720w.jpg?source=1940ef5c"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;  频繁记录着，因为热爱生活？嗯，我要朝这个目标努力。&lt;/p&gt;
&lt;p&gt;《今生是第一次》可以说是一部很治愈的韩剧啦，虽然还没有看完，但是现在写一写感受也不为过叭。&lt;/p&gt;
&lt;p&gt;从前总觉得时间是一种很残忍的东西，因为亲人、好朋友或是自己都会因为时间而消失或改变。每当很美好的时</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>日常心情【1】</title>
    <link href="http://example.com/2021/02/18/%E6%97%A5%E5%B8%B8%E5%BF%83%E6%83%85%E3%80%901%E3%80%91/"/>
    <id>http://example.com/2021/02/18/%E6%97%A5%E5%B8%B8%E5%BF%83%E6%83%85%E3%80%901%E3%80%91/</id>
    <published>2021-02-18T12:45:49.000Z</published>
    <updated>2021-11-27T08:34:24.467Z</updated>
    
    <content type="html"><![CDATA[<ul><li>2021/02/18 日常</li></ul><p>去年的时候老师就发短信给我说寒假希望看看我，一直把这件事发在心里，今天终于有勇气去问问老师有没有时间，听到声音的一刻仿佛回到了高中那黑白斑驳的黑板前，后桌坐的还是你。时间无法衡量人与人之间的感情，却可以检验什么是值得去珍惜的。因为自己认知的局限，会有很多遗憾或者说无意义的事情，但这或许也算一种成长。生活并不总是耀眼的颜色对吧。回想以往度过的时光，大多时候是比较单调的颜色，而总会因为他人善意的温暖带来一些暖色，使得在即使在黑暗中也能够看到一点光芒。困难对我来说也是一种成长的机会，因为看到脚底的阴影，才知道原来周围是有光的。以往认为无法理解的事情，现在也会赋予它合适的理由；以往认为每个人美好的品质是与生俱来的，现在也会体会到也许正是认识到不美好的存在才要努力变得温柔美好；以往认为成为他人心目中的自己或许才是正确的选择，现在发现原来真实的自己也能得到别人的肯定。每年的烟花都是相似的，但却因为心境的不同有不同的感受。正如其出现的意义一样，美好总是转瞬即逝的，但我们总要仰望星空，最近发现值得自己学习的东西太多了，希望自己都有勇气去尝试呀，加油加油:sparkles::sparkles::sparkles:</p><ul><li>List 1：<ul><li>每周记得看看有趣的TED视频，也可以学到一点其他领域的知识。</li><li>敢于尝试之前自己没有做过的事情。</li><li>坚持有规律地跑步吧，放假后总是间断性地跑步。</li><li>花更多的时间在思考与行动上（emm这也是很少记录的原因了）。</li><li>想到有时间再补充吧。</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;2021/02/18 日常&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;去年的时候老师就发短信给我说寒假希望看看我，一直把这件事发在心里，今天终于有勇气去问问老师有没有时间，听到声音的一刻仿佛回到了高中那黑白斑驳的黑板前，后桌坐的还是你。时间无法衡量人与人之间的感情，却可以检验</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://example.com/2021/02/02/hello-world/"/>
    <id>http://example.com/2021/02/02/hello-world/</id>
    <published>2021-02-02T12:05:54.854Z</published>
    <updated>2021-02-02T12:05:54.855Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
  </entry>
  
</feed>
